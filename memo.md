1주차
- 주석 지우고 다시 코드 만드는 건 며칠 간격 두고 해보기.
- 쉘의 괄호 = 현재 있는 환경을 의미함.
- pip는 패키지를 관리하는 용도로 쓴다.
- 파이참은 정말 많은 기능을 제공하지만 무겁다.
- remote - 서버 연결하는 것. 아래 두 개는 들어가서 관리하는 것.
- 파이토치는 연구용으론 좋으나 서비스용으로 활용하려고 하면 좀 더 복잡한 과정을 거쳐야 한다. 
- 텐서: 데이터이자 학습 파라미터. 
- 넘파이에서 가져온 값을 파이토치에서 바꾸면, 넘파이에서도 바뀐다. 
- 따라서 원본 데이터가 변경되지 않게 조심해야 함. 
- 이럴 땐 b=a.copy() 같은 식으로 해야 함. 
 
- 넘파이형은 array([1,2,3]) 같은 형식. 
- inspection 중요! 데이터의 생김새를 많이 확인하므로 자주 씀.
- inplace = 덮어쓴다.
- 파이토치에선 자료형이 같아야 연산이 된다. 
- casting = 형변환. float32가 기본이지만 이걸 경량화할 땐 float16으로 함. 
  a.to('cuda')= cuda라는 디바이스로 보낸다. 
- view= 데이터를 공유하게 됨. 변경 시 문제 생길 수 있으므로 reshape 쓰는 게 더 안전.
- stack 차원을 하나 만들고 그 차원을 기준으로 합침. 그래서 dim=1로 두고 두 개를 합친다고 하면 새 차원의 값이 2가 됨. 
- indexing = 차원을 어디까지 유지해서 가져오는지의 문제. 1이라고 하면 한 차원만, 1:2이라고 하면 2차원까지. 

- 숙제: 문제풀이 : 연산 숙제 파일.

- class 형태의 모델 생성 시 init과 forward는 필수. 
- 데이터셋 = 하나의 데이터씩 정리(전처리)한 후 캐시 메모리에 쌓아둔다. 데이터 로더는 그걸 가져와서 인공지능 모델에 넣는다. 
- 배치 사이즈 = 그래서 얼마나 데이터가 쌓였을 때 데이터 로더가 데이터를 가져가서 모델에 넣을지 정하는 것. 
- 데이터로더는 이미 구현된 걸 그대로 쓰는 게 대부분. 
- 우리가 많이 손봐야 하는 건 데이터셋. 내 상황에 맞게 데이터를 불러오는 것. 
- 데이터를 바로 가져오는 경우 / 경로만 가져온 뒤 나중에 불러오는 경우. 
데이터가 적을 경우에는 후자가 더 느리나(전자는 데이터를 바로 가져오니까), 데이터가 많을 경우에는 후자가 더 낫다(전자는 데이터를 다 올려버리니까).
- num_worker dataset을 몇개 쓸거냐. 
- 데이터마다 크기의 차이가 있다. 그럼에도 데이터로더는 이걸 다 동일한 크기로 만들어서 넘겨줘야만 한다. 이렇게 데이터로더 단계에서 전처리를 해주는 게 collate_fn. 패딩 같은 거. 
- drop_last는 배치사이즈랑 학습 횟수의 차이 생겨서 남거나 모자란 게 있을 때 어떻게 할지. 
- nn.module - 모든 클래스가 얘를 상속받음. 그래서 얘가 모델이 원활하게 연결되도록 함. 로스, 옵티마이저 등등...이 잘 연결되도록 함. 
- 다른 걸 상속받고 싶으면 이중상속으로 해야 함. 
- no_grad:평가할 때 사용함. 
그러나 eval하곤 다름. 예를 들어 드롭아웃에 대해서 끊을지 안 끊을지의 차이. 
-  requires grad = int는 미분이 안 되니 여기선 못씀.
-  옵티마이저 - 러닝 레이트를 몇으로 둘 건지, w값을 어떻게 업데이트할 건지가 문제.
-  러닝레이트 값을 다르게 준다. 모델 안에 새로 들어온 모듈에는 더 크게 러닝레이트를 준다던가. 학습의 처음과 나중에 있어 러닝레이트를 다르게 준다던가. 
-  nn.functional은 forward에서(만) 쓴다. 함수다. 
-  nn은 init 과정에서 쓴다. 클래스다. 
-  nn.conv2d은 학습 가능한 객체. w랑 bias가 담겨있음. 
반면 f.conv2d는 그냥 수식. 
- rgb는 표준화를 해줘야 함. 그래야 걔네끼리 비슷한 정도의 분포를 맞춰서 학습을 더 잘 시킬 수 있음. 
- ####docs 보는 걸 습관화하기.